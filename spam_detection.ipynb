{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eaf72732",
   "metadata": {},
   "source": [
    "# Email spam detection (  Lazy Text Predict ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4028d3a",
   "metadata": {},
   "source": [
    "Text classification autoML.\n",
    "\n",
    "Lazy text predict a actuellement cinq modèles NLP codés en dur :\n",
    "\n",
    "Trois sont basés sur des réseaux neuronaux:\n",
    "\n",
    "- Bert\n",
    "\n",
    "- Albert\n",
    "\n",
    "- Roberta \n",
    "\n",
    "Deux sont basés sur des vecteurs de comptage :\n",
    "\n",
    "- Bayésien naïf multinomial \n",
    "\n",
    "- Support Vector Machine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8939f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isslamkhatir/anaconda3/envs/conda/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import lazypredict\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file\n",
    "from lazytextpredict import basic_classification\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1a99b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>605</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2349</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3624</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4685</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5166</th>\n",
       "      <td>1518</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: put the 10 on the ft\\r\\nthe transport...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5167</th>\n",
       "      <td>404</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: 3 / 4 / 2000 and following noms\\r\\nhp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5168</th>\n",
       "      <td>2933</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: calpine daily gas nomination\\r\\n&gt;\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5169</th>\n",
       "      <td>1409</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: industrial worksheets for august 2000...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5170</th>\n",
       "      <td>4807</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: important online banking alert\\r\\ndea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5171 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 label                                               text   \n",
       "0            605   ham  Subject: enron methanol ; meter # : 988291\\r\\n...  \\\n",
       "1           2349   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...   \n",
       "2           3624   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...   \n",
       "3           4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
       "4           2030   ham  Subject: re : indian springs\\r\\nthis deal is t...   \n",
       "...          ...   ...                                                ...   \n",
       "5166        1518   ham  Subject: put the 10 on the ft\\r\\nthe transport...   \n",
       "5167         404   ham  Subject: 3 / 4 / 2000 and following noms\\r\\nhp...   \n",
       "5168        2933   ham  Subject: calpine daily gas nomination\\r\\n>\\r\\n...   \n",
       "5169        1409   ham  Subject: industrial worksheets for august 2000...   \n",
       "5170        4807  spam  Subject: important online banking alert\\r\\ndea...   \n",
       "\n",
       "      label_num  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             1  \n",
       "4             0  \n",
       "...         ...  \n",
       "5166          0  \n",
       "5167          0  \n",
       "5168          0  \n",
       "5169          0  \n",
       "5170          1  \n",
       "\n",
       "[5171 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= pd.read_csv('/Users/isslamkhatir/Downloads/spam_ham_dataset.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb26daa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#supprimer les colonnes Unnamed et label_num\n",
    "data = data.drop('Unnamed: 0', axis=1)\n",
    "data = data.drop(['label_num'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e62f1015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5166</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: put the 10 on the ft\\r\\nthe transport...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5167</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: 3 / 4 / 2000 and following noms\\r\\nhp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5168</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: calpine daily gas nomination\\r\\n&gt;\\r\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5169</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: industrial worksheets for august 2000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5170</th>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: important online banking alert\\r\\ndea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5171 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "0      ham  Subject: enron methanol ; meter # : 988291\\r\\n...\n",
       "1      ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...\n",
       "2      ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...\n",
       "3     spam  Subject: photoshop , windows , office . cheap ...\n",
       "4      ham  Subject: re : indian springs\\r\\nthis deal is t...\n",
       "...    ...                                                ...\n",
       "5166   ham  Subject: put the 10 on the ft\\r\\nthe transport...\n",
       "5167   ham  Subject: 3 / 4 / 2000 and following noms\\r\\nhp...\n",
       "5168   ham  Subject: calpine daily gas nomination\\r\\n>\\r\\n...\n",
       "5169   ham  Subject: industrial worksheets for august 2000...\n",
       "5170  spam  Subject: important online banking alert\\r\\ndea...\n",
       "\n",
       "[5171 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cc809d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "ham     3672\n",
       "spam    1499\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compter les hams et les spams dans la dataset\n",
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6f05777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5171</td>\n",
       "      <td>5171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>4993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: calpine daily gas nomination\\r\\n&gt;\\r\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3672</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               text\n",
       "count   5171                                               5171\n",
       "unique     2                                               4993\n",
       "top      ham  Subject: calpine daily gas nomination\\r\\n>\\r\\n...\n",
       "freq    3672                                                 20"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f7be85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5171 entries, 0 to 5170\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   5171 non-null   object\n",
      " 1   text    5171 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 80.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "440da906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# somme des lignes dupliquées \n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "399898da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppression des lignes dupliquées \n",
    "data=data.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66618e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4993, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d709a89-1d83-470d-8a99-5ce8c70f5a10",
   "metadata": {},
   "source": [
    "On a 4993 lignes et 2 colonnes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f8d97e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m1/5ps2227d199g23dsl003lzkh0000gn/T/ipykernel_8814/3113428461.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['label'] = data['label'].replace(['ham'],'non-spam')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       non-spam\n",
       "1       non-spam\n",
       "2       non-spam\n",
       "3           spam\n",
       "4       non-spam\n",
       "          ...   \n",
       "5165    non-spam\n",
       "5166    non-spam\n",
       "5167    non-spam\n",
       "5169    non-spam\n",
       "5170        spam\n",
       "Name: label, Length: 4993, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remplacement de 'ham' par 'non-spam' \n",
    "data['label'] = data['label'].replace(['ham'],'non-spam')\n",
    "data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fabe4c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "non-spam    3531\n",
       "spam        1462\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compter le nombre de spam et non-spam\n",
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d7bfe6",
   "metadata": {},
   "source": [
    "# Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb558862",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "punct = []\n",
    "for char in string.punctuation:\n",
    "    punct.append(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eac4f426",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def cleaning(text):\n",
    "\n",
    "    # remove multiple space, tabs, newlines\n",
    "    text = re.sub('\\s+',' ',str(text))\n",
    "    \n",
    "    # remove links\n",
    "    text = text.replace(\"http://\", \" \").replace(\"https://\", \" \")\n",
    "    \n",
    "    # remove special characters\n",
    "    text = text.encode('ascii', 'replace').decode('ascii')\n",
    "    text = ' '.join(re.sub(\"([@#][A-Za-z0-9]+)|(\\w+:\\/\\/\\S+)\",\" \", text).split())\n",
    "    \n",
    "    # remove punctuation\n",
    "    text = ''.join([word for word in text if word not in punct])\n",
    "    \n",
    "    #remove single character\n",
    "    text = re.sub(r\"\\b[a-zA-Z]\\b\", \"\",str(text))\n",
    "    \n",
    "    #remove numbers\n",
    "    text = re.sub(r\"\\d+\", \"\",str(text))\n",
    "        \n",
    "    #remove multiple spaces (again)\n",
    "    text = re.sub('\\s+',' ',str(text))\n",
    "    \n",
    "    return str(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1868d71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m1/5ps2227d199g23dsl003lzkh0000gn/T/ipykernel_8814/2871223393.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['text_cleaned'] = data['text'].apply(lambda x: cleaning(x))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>Subject enron methanol meter this is follow up...</td>\n",
       "      <td>non-spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>Subject hpl nom for january see attached file ...</td>\n",
       "      <td>non-spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>Subject neon retreat ho ho ho we re around to ...</td>\n",
       "      <td>non-spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>Subject photoshop windows office cheap main tr...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>Subject re indian springs this deal is to book...</td>\n",
       "      <td>non-spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5165</th>\n",
       "      <td>Subject: fw : crosstex energy , driscoll ranch...</td>\n",
       "      <td>Subject fw crosstex energy driscoll ranch mete...</td>\n",
       "      <td>non-spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5166</th>\n",
       "      <td>Subject: put the 10 on the ft\\r\\nthe transport...</td>\n",
       "      <td>Subject put the on the ft the transport volume...</td>\n",
       "      <td>non-spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5167</th>\n",
       "      <td>Subject: 3 / 4 / 2000 and following noms\\r\\nhp...</td>\n",
       "      <td>Subject and following noms hpl can take the ex...</td>\n",
       "      <td>non-spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5169</th>\n",
       "      <td>Subject: industrial worksheets for august 2000...</td>\n",
       "      <td>Subject industrial worksheets for august activ...</td>\n",
       "      <td>non-spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5170</th>\n",
       "      <td>Subject: important online banking alert\\r\\ndea...</td>\n",
       "      <td>Subject important online banking alert dear va...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4993 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text   \n",
       "0     Subject: enron methanol ; meter # : 988291\\r\\n...  \\\n",
       "1     Subject: hpl nom for january 9 , 2001\\r\\n( see...   \n",
       "2     Subject: neon retreat\\r\\nho ho ho , we ' re ar...   \n",
       "3     Subject: photoshop , windows , office . cheap ...   \n",
       "4     Subject: re : indian springs\\r\\nthis deal is t...   \n",
       "...                                                 ...   \n",
       "5165  Subject: fw : crosstex energy , driscoll ranch...   \n",
       "5166  Subject: put the 10 on the ft\\r\\nthe transport...   \n",
       "5167  Subject: 3 / 4 / 2000 and following noms\\r\\nhp...   \n",
       "5169  Subject: industrial worksheets for august 2000...   \n",
       "5170  Subject: important online banking alert\\r\\ndea...   \n",
       "\n",
       "                                           text_cleaned     label  \n",
       "0     Subject enron methanol meter this is follow up...  non-spam  \n",
       "1     Subject hpl nom for january see attached file ...  non-spam  \n",
       "2     Subject neon retreat ho ho ho we re around to ...  non-spam  \n",
       "3     Subject photoshop windows office cheap main tr...      spam  \n",
       "4     Subject re indian springs this deal is to book...  non-spam  \n",
       "...                                                 ...       ...  \n",
       "5165  Subject fw crosstex energy driscoll ranch mete...  non-spam  \n",
       "5166  Subject put the on the ft the transport volume...  non-spam  \n",
       "5167  Subject and following noms hpl can take the ex...  non-spam  \n",
       "5169  Subject industrial worksheets for august activ...  non-spam  \n",
       "5170  Subject important online banking alert dear va...      spam  \n",
       "\n",
       "[4993 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text_cleaned'] = data['text'].apply(lambda x: cleaning(x))\n",
    "data = data[['text', 'text_cleaned', 'label']]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93005085-a557-4e10-a8cd-6ba6d94a724b",
   "metadata": {},
   "source": [
    "On a nettoyé la colonne text par supprimer espace multiple, onglets, nouvelles lignes, caractères spéciaux, ponctuation, caractère unique, nombres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1b90707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'label'], dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#la nouvelle data avec 2 colonnes  : text et label \n",
    "data = data.drop(['text'], axis=1)\n",
    "data = data.rename(columns = {'text_cleaned' : 'text'})\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39d1b814",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['text']\n",
    "y = data['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3511c6-66ec-4b30-8e30-e10cd39f5063",
   "metadata": {},
   "source": [
    "# Lazy Text Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "361b191f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting pandas series to list\n",
      "converting pandas series to list\n",
      "X_train length: 4493\n",
      "X_test length: 500\n",
      "Y_train length: 4493\n",
      "Y_test length: 500\n"
     ]
    }
   ],
   "source": [
    "trial=basic_classification.LTP(Xdata=X,Ydata=y, csv=None, xlsx=None, x_col='X', y_col='y', models='all') \n",
    "# You can choose between 'transformers'-based, 'count-vectorizer'-based, and 'all' models.\n",
    "# Xdata is a list of text, and Ydata is a list of corresponding labels.\n",
    "# x_col and y_col are strings that specify the columns of the text and label columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10b1d7cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on a dataset with 2 labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.97s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  3.28it/s]\n",
      "/Users/isslamkhatir/anaconda3/envs/conda/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='281' max='281' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [281/281 1:21:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 02:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.10363858938217163, 'eval_accuracy': 0.978, 'eval_f1': 0.9777882519922527, 'eval_precision': 0.9783644809072812, 'eval_recall': 0.978, 'eval_full_report': {'0': {'precision': 0.9724517906336089, 'recall': 0.9971751412429378, 'f1-score': 0.9846582984658299, 'support': 354}, '1': {'precision': 0.9927007299270073, 'recall': 0.9315068493150684, 'f1-score': 0.96113074204947, 'support': 146}, 'accuracy': 0.978, 'macro avg': {'precision': 0.9825762602803081, 'recall': 0.9643409952790032, 'f1-score': 0.97289452025765, 'support': 500}, 'weighted avg': {'precision': 0.9783644809072812, 'recall': 0.978, 'f1-score': 0.9777882519922527, 'support': 500}}, 'eval_runtime': 139.9348, 'eval_samples_per_second': 3.573, 'eval_steps_per_second': 0.057, 'epoch': 1.0}\n",
      "Training on a dataset with 2 labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.decoder.bias', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.decoder.weight', 'predictions.dense.bias', 'predictions.bias']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.39s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.51it/s]\n",
      "/Users/isslamkhatir/anaconda3/envs/conda/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='281' max='281' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [281/281 57:52, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 02:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.045593563467264175, 'eval_accuracy': 0.988, 'eval_f1': 0.988, 'eval_precision': 0.988, 'eval_recall': 0.988, 'eval_full_report': {'0': {'precision': 0.9915254237288136, 'recall': 0.9915254237288136, 'f1-score': 0.9915254237288136, 'support': 354}, '1': {'precision': 0.9794520547945206, 'recall': 0.9794520547945206, 'f1-score': 0.9794520547945206, 'support': 146}, 'accuracy': 0.988, 'macro avg': {'precision': 0.9854887392616671, 'recall': 0.9854887392616671, 'f1-score': 0.9854887392616671, 'support': 500}, 'weighted avg': {'precision': 0.988, 'recall': 0.988, 'f1-score': 0.988, 'support': 500}}, 'eval_runtime': 142.199, 'eval_samples_per_second': 3.516, 'eval_steps_per_second': 0.056, 'epoch': 1.0}\n",
      "Training on a dataset with 2 labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)olve/main/vocab.json: 100%|██████████| 899k/899k [00:00<00:00, 1.47MB/s]\n",
      "Downloading (…)olve/main/merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 3.94MB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 481/481 [00:00<00:00, 147kB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 501M/501M [01:44<00:00, 4.78MB/s] \n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'roberta.pooler.dense.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.03s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.23it/s]\n",
      "/Users/isslamkhatir/anaconda3/envs/conda/lib/python3.8/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='281' max='281' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [281/281 1:20:16, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 02:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09367190301418304, 'eval_accuracy': 0.976, 'eval_f1': 0.9761390466356908, 'eval_precision': 0.9766070780399274, 'eval_recall': 0.976, 'eval_full_report': {'0': {'precision': 0.9913793103448276, 'recall': 0.9745762711864406, 'f1-score': 0.982905982905983, 'support': 354}, '1': {'precision': 0.9407894736842105, 'recall': 0.9794520547945206, 'f1-score': 0.959731543624161, 'support': 146}, 'accuracy': 0.976, 'macro avg': {'precision': 0.966084392014519, 'recall': 0.9770141629904806, 'f1-score': 0.9713187632650719, 'support': 500}, 'weighted avg': {'precision': 0.9766070780399274, 'recall': 0.976, 'f1-score': 0.9761390466356908, 'support': 500}}, 'eval_runtime': 141.3463, 'eval_samples_per_second': 3.537, 'eval_steps_per_second': 0.057, 'epoch': 1.0}\n",
      "Training on a dataset with 2 labels\n",
      "ERROR\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "best parameters are:\n",
      "{'clf__alpha': 0.001, 'clf__penalty': 'l2', 'tfidf__use_idf': True, 'vect__ngram_range': (1, 1)}\n",
      "{'eval_loss': 0.026, 'eval_accuracy': 0.974, 'eval_f1': 0.9692221732933695, 'eval_precision': 0.960325713542924, 'eval_recall': 0.9796261899233805, 'eval_full_report': '              precision    recall  f1-score   support\\n\\n           0       1.00      0.97      0.98       354\\n           1       0.92      0.99      0.96       146\\n\\n    accuracy                           0.97       500\\n   macro avg       0.96      0.98      0.97       500\\nweighted avg       0.98      0.97      0.97       500\\n'}\n",
      "Training on a dataset with 2 labels\n",
      "ERROR\n",
      "best parameters are:\n",
      "{'clf__alpha': 0.01, 'clf__fit_prior': False, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}\n",
      "{'eval_loss': 0.016, 'eval_accuracy': 0.984, 'eval_f1': 0.9807288354435258, 'eval_precision': 0.9788467444717445, 'eval_recall': 0.9826638805046048, 'eval_full_report': '              precision    recall  f1-score   support\\n\\n           0       0.99      0.99      0.99       354\\n           1       0.97      0.98      0.97       146\\n\\n    accuracy                           0.98       500\\n   macro avg       0.98      0.98      0.98       500\\nweighted avg       0.98      0.98      0.98       500\\n'}\n"
     ]
    }
   ],
   "source": [
    "trial.run(training_epochs=1)\n",
    "#This trains the models specified above on the data you loaded. \n",
    "#Here you can specify the number of training epochs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebabb57-5240-42a0-9c0a-933306090837",
   "metadata": {},
   "source": [
    "# Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2c8a6e6-0284-4110-b98b-e10dc8ce0480",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['text']\n",
    "y = data['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560a4c97-351b-4a03-8097-2fb8be16095a",
   "metadata": {},
   "source": [
    "# Data preprocessing with CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bf64f0-5e4a-42c0-b3ad-d5756dce35ec",
   "metadata": {},
   "source": [
    "Convert a collection of text documents to a matrix of token counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61477999-c998-4516-bb00-c78e78597684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "count_vec = CountVectorizer()\n",
    "X_train_counts = count_vec.fit_transform(X_train)\n",
    "print(X_train_counts.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df172b16-366c-4986-a13f-8202e9620831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "print(X_train_tfidf.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b94f84f-80e4-4458-9bb9-f35765e3dc9c",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49ca84fd-584a-4452-869e-a0252a814a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6cb5db3-c13a-46af-8a1c-a3f337c77d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_counts = count_vec.transform(X_test)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "786568ba-b725-466d-b90a-d8a983ff3ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('count_vec', CountVectorizer()), \n",
    "                     ('tfidf_transformer', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier(tol=None, n_jobs=-1))]).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d977a67-b99e-4289-a897-1baf3d0fd465",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c53185-64a2-4608-87e9-473d792f1a84",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "915caa25-25ec-4cd7-86af-e5c55594cf56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    non-spam       0.99      0.98      0.99       377\n",
      "        spam       0.94      0.98      0.96       123\n",
      "\n",
      "    accuracy                           0.98       500\n",
      "   macro avg       0.97      0.98      0.97       500\n",
      "weighted avg       0.98      0.98      0.98       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['non-spam', 'spam']\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4da9589-f10a-4a9c-ab28-1e22a6fc8199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "617039d7-e262-4e36-83b1-5eb8584bef6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "490\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred, normalize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bdefeb93-b757-44d6-9060-172be56adc0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spam'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[490]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "918ebab1-01e7-4870-b7d8-63b7e356afc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'non-spam'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[490]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "694077c5-b66a-4397-ac50-97b3c9f4adff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[370   7]\n",
      " [  3 120]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred),annot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
